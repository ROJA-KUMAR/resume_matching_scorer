{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "importing the necessary libraries"
      ],
      "metadata": {
        "id": "Ev9xayXx11Wm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN0Dt4dC2Nad",
        "outputId": "48df3d72-7943-429c-dbe5-e1a786c8880b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vrvbm-3a1cNp"
      },
      "outputs": [],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import PyPDF2\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articles = pd.read_csv('/content/training_data.csv')\n",
        "print(articles.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvyKNYs14wJc",
        "outputId": "ec066f4c-06a7-471a-ab85-3137c98ecc51"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  company_name                                    job_description  \\\n",
            "0       Google  minimum qualifications\\r\\nbachelors degree or ...   \n",
            "1        Apple  description\\r\\nas an asc you will be highly in...   \n",
            "2      Netflix  its an amazing time to be joining netflix as w...   \n",
            "3  Robert Half  description\\r\\n\\r\\nweb designers looking to ex...   \n",
            "4    TrackFive  at trackfive weve got big goals were on a miss...   \n",
            "\n",
            "                              position_title  description_length  \\\n",
            "0                           Sales Specialist                2727   \n",
            "1                 Apple Solutions Consultant                 828   \n",
            "2  Licensing Coordinator - Consumer Products                3205   \n",
            "3                               Web Designer                2489   \n",
            "4                              Web Developer                3167   \n",
            "\n",
            "                                      model_response  \n",
            "0   {\\r\\n  \"Core Responsibilities\": \"Responsible ...  \n",
            "1   {\\r\\n  \"Core Responsibilities\": \"as an asc yo...  \n",
            "2   {\\r\\n  \"Core Responsibilities\": \"Help drive b...  \n",
            "3   {\\r\\n  \"Core Responsibilities\": \"Designing we...  \n",
            "4   {\\r\\n  \"Core Responsibilities\": \"Build and la...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-q0pXwo5S_p",
        "outputId": "b9e09c55-fe5d-4448-ff29-7d2e5e0ff506"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = list(articles['job_description'])\n",
        "tagged_data = [TaggedDocument(words = word_tokenize(_d.lower()), tags = [str(i)]) for i, _d in enumerate(data)]"
      ],
      "metadata": {
        "id": "7uMPUf0k453_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Doc2vec model is initialized as follows"
      ],
      "metadata": {
        "id": "D_hYWsY45cWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec(vector_size = 50,\n",
        "min_count = 10,\n",
        "epochs = 50\n",
        ")"
      ],
      "metadata": {
        "id": "GMj8kqdA5bRk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vocabulary building"
      ],
      "metadata": {
        "id": "-YHXRQtn5oQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.build_vocab(tagged_data)\n",
        "k = model.wv.key_to_index\n",
        "print(len(k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U85KIPUb5i1t",
        "outputId": "9254ce73-959c-47d9-9108-0c6d0b150fa6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(tagged_data,\n",
        "total_examples = model.corpus_count,\n",
        "epochs = model.epochs)\n",
        "model.save('doc2vec.model')\n",
        "print(\"Model saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2fLrGGTnkxM",
        "outputId": "5e637d10-c66d-4131-fc0e-895fc0070fcd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resume_path = '/content/717821i239-Ramasamy_V.pdf'\n",
        "resume = ''\n",
        "# Open the PDF file\n",
        "with open(resume_path, 'rb') as file:\n",
        "    # Create a PdfReader object\n",
        "    pdfReader = PyPDF2.PdfReader(file)\n",
        "\n",
        "    # Iterate through each page\n",
        "    for i in range(len(pdfReader.pages)):\n",
        "        # Access the page using indexing\n",
        "        pageObj = pdfReader.pages[i]\n",
        "\n",
        "        # Extract text from the page and add it to the resume string\n",
        "        resume += pageObj.extract_text()"
      ],
      "metadata": {
        "id": "dXrUFwIAnk9Y"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume = resume.lower()\n",
        "resume = re.sub('[^a-z]', ' ', resume)"
      ],
      "metadata": {
        "id": "QfwQXtZ1nlA8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_data(url):\n",
        "  list1 = []\n",
        "  count = 0\n",
        "  resp = requests.get(url)\n",
        "  if resp.status_code == 200:\n",
        "      soup = BeautifulSoup(resp.text,'html.parser')\n",
        "      l = soup.find(class_ = 'av-company-description-page mb-2')\n",
        "      web = ''.join([i.text for i in l.find_all(['p', 'li'])])\n",
        "      list1.append(web)\n",
        "      return web\n",
        "  else:\n",
        "      print(\"Error\")\n",
        "jd_links = ['https://datahack.analyticsvidhya.com/jobathon/cropin/data-scientist-85']\n",
        "\n",
        "jd_df = pd.DataFrame(columns = ['links', 'data'])\n",
        "jd_df['links'] = jd_links\n",
        "\n",
        "#Extracting the JD data from the links:\n",
        "for i in range(len(jd_df)):\n",
        "  jd_df['data'][i] = extract_data(jd_df['links'][i])"
      ],
      "metadata": {
        "id": "_4YvH1NhnlDc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the text into lower case\n",
        "jd_df.loc[:,\"data\"] = jd_df.data.apply(lambda x : str.lower(x))\n",
        "\n",
        "#Removing the punctuations from the text\n",
        "jd_df.loc[:,\"data\"] = jd_df.data.apply(lambda x : \" \".join(re.findall('[\\w]+',x))\n",
        ")\n",
        "#Removing the numerics present in the text\n",
        "jd_df.loc[:,\"data\"] = jd_df.data.apply(lambda x : re.sub(r'\\d+','',x))"
      ],
      "metadata": {
        "id": "0ZM5GSMlqYce"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import norm\n"
      ],
      "metadata": {
        "id": "QPoSkc3yq05h"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doc2Vec.load('doc2vec.model')\n",
        "v1 = model.infer_vector(resume.split())\n",
        "v2 = model.infer_vector(jd_df['data'][0].split())\n",
        "cosine_similarity = (np.dot(np.array(v1), np.array(v2))) / (norm(np.array(v1)) * norm(np.array(v2)))\n",
        "print(round(cosine_similarity, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NlbU2jKqYff",
        "outputId": "ed4c6e02-97ad-4b36-bed3-cdfae7e86bf4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.513\n"
          ]
        }
      ]
    }
  ]
}